import os
import sys
import json
import shutil
import re # â¬…ï¸ [ä¿®æ­£] re ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import time # â¬…ï¸ [ä¿®æ­£] ãƒªãƒˆãƒ©ã‚¤ã®ãŸã‚ã« time ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from google import genai
from datetime import datetime
from utils.client_utils import setup_client

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from agents.agent_03_generation import generate_single_page_html
from agents.agent_04_improvement import (
    analyze_article_structure,
    generate_article_purpose,
    select_priority_section_by_data,
    generate_priority_article_titles
)
from utils.file_utils import (
    get_existing_article_count,
    integrate_content_data,
    save_to_markdown,
    load_markdown_table_to_list
)
from utils.analysis_utils import create_placeholder_data
from main_03_inject_tags import main as inject_tags_main

# --- 0. è¨­å®š ---
PROJECT_ROOT_PATH = "/content/MySiteGen-Agent" 
BASE_DIR = os.path.join(PROJECT_ROOT_PATH, "output", "docs")
REPORTS_DIR = os.path.join(PROJECT_ROOT_PATH, "output", "output_reports")

REPORT_FILE = os.path.join(REPORTS_DIR, "planned_articles.md")
DEFAULT_ARTICLE_COUNT = 3

def load_corporate_identity():
    # ... (ã“ã®é–¢æ•°ã¯å¤‰æ›´ãªã—) ...
    identity_file = os.path.join(REPORTS_DIR, "01_identity.md")
    try:
        with open(identity_file, 'r', encoding='utf-8') as f:
            identity = f.read()
        print(f"âœ… æ³•äººæ ¼ã‚’ {identity_file} ã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
        return identity
    except Exception as e:
        print(f"âŒ æ³•äººæ ¼ãƒ•ã‚¡ã‚¤ãƒ« ({identity_file}) ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
        # (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)
        try:
            from agents.agent_01_identity import generate_corporate_identity
            opinion_path = os.path.join(PROJECT_ROOT_PATH, "config", "opinion.txt")
            with open(opinion_path, 'r', encoding='utf-8') as f:
                RAW_VISION_INPUT = f.read()
            client = setup_client()
            if client:
                print("âš ï¸ [ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯] æ³•äººæ ¼ã‚’APIã§å†ç”Ÿæˆã—ã¾ã™ã€‚")
                return generate_corporate_identity(client, RAW_VISION_INPUT, 'personal')
            else:
                raise Exception("ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—")
        except Exception as e_fallback:
            print(f"âŒ ä»£æ›¿å‡¦ç†ã‚‚å¤±æ•—: {e_fallback}ã€‚ãƒ€ãƒŸãƒ¼ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            return "ãƒ‘ãƒ¼ãƒ‘ã‚¹: ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹å€‹äººã®ç”Ÿæ´»æœ€é©åŒ–ã€‚ ãƒˆãƒ¼ãƒ³: è«–ç†çš„ã€å…ˆé€²çš„ã€‚"

def main():
    print(f"--- ğŸ”„ HPæ”¹å–„ã‚µã‚¤ã‚¯ãƒ« (ãƒ•ã‚§ãƒ¼ã‚º5-8) [æˆ¦ç•¥çš„ãƒãƒ©ãƒ³ã‚¹ãƒ¢ãƒ¼ãƒ‰] é–‹å§‹ ---")

    # --- 0. ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ– ---
    gemini_client = setup_client()
    if gemini_client is None: sys.exit(1)

    # --- (å‰æ) æ³•äººæ ¼ã®å–å¾— ---
    CORPORATE_IDENTITY = load_corporate_identity()

    if "æ³•äººæ ¼" in CORPORATE_IDENTITY or "corporate" in CORPORATE_IDENTITY:
        SITE_TYPE = 'corporate'
    else:
        SITE_TYPE = 'personal'
    print(f"âœ… ã‚µã‚¤ãƒˆã‚¿ã‚¤ãƒ—ã‚’ '{SITE_TYPE}' ã¨è‡ªå‹•åˆ¤å®šã—ã¾ã—ãŸã€‚")

    # --- 5a. æˆ¦ç•¥ï¼ˆAS-ISåˆ†æï¼‰---
    print(f"\n--- [ãƒ•ã‚§ãƒ¼ã‚º5a: AS-ISåˆ†æ] è¨ˆç”»ãƒ•ã‚¡ã‚¤ãƒ« ({REPORT_FILE}) ã‚’èª­ã¿è¾¼ã¿ä¸­ ---")
    processed_articles = None
    if os.path.exists(REPORT_FILE):
        processed_articles = load_markdown_table_to_list(REPORT_FILE)

    if processed_articles:
        processed_articles = [
            row for row in processed_articles 
            if not row.get('file_name', '').startswith(':---')
        ]
        print(f"âœ… æ—¢å­˜ã®è¨ˆç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ {len(processed_articles)} ä»¶ã®ç›®çš„ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚ï¼ˆAPIã‚³ãƒ¼ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰")
    else:
       # (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ ... å¤‰æ›´ãªã—)
        print(f"âš ï¸ è¨ˆç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        print(f"--- [ãƒ•ã‚§ãƒ¼ã‚º5a ä»£æ›¿] æ—¢å­˜ã‚µã‚¤ãƒˆ ({BASE_DIR}) ã‚’ã‚¹ã‚­ãƒ£ãƒ³ä¸­ ---")
        processed_articles = []
        TARGET_EXTENSIONS = ('.html', '.htm')
        if not os.path.isdir(BASE_DIR):
            print(f"âŒ åˆ†æå¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª {BASE_DIR} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            sys.exit(1)
        current_time_iso = datetime.now().isoformat()
        for root, _, files in os.walk(BASE_DIR):
            for filename in files:
                if filename.lower().endswith(TARGET_EXTENSIONS):
                    full_path = os.path.join(root, filename)
                    article_data, error = analyze_article_structure(full_path)
                    if article_data:
                        purpose = generate_article_purpose(gemini_client, article_data, CORPORATE_IDENTITY)
                        processed_articles.append({
                            "file_name": os.path.relpath(full_path, BASE_DIR).replace(os.path.sep, '/'),
                            "title": article_data['page_title'],
                            "summary": purpose,
                            "created_at": current_time_iso,
                            "updated_at": ""
                        })
        print(f"\nâœ… [ãƒ•ã‚§ãƒ¼ã‚º5a ä»£æ›¿å®Œäº†] åˆè¨ˆ {len(processed_articles)} ä»¶ã®ç›®çš„ã‚’APIã§å†å®šç¾©ã—ã¾ã—ãŸã€‚")
    
    # 5a-2. ã€Œæˆ¦ç•¥çš„ãƒãƒ©ãƒ³ã‚¹ã€ã®æ•°å€¤åŒ– (å¤‰æ›´ãªã—)
    print(f"\n--- [ãƒ•ã‚§ãƒ¼ã‚º5a-2: æˆ¦ç•¥çš„ãƒãƒ©ãƒ³ã‚¹ã®åˆ†æ] ---")
    # ... (hub_counts, balance_report ã®ãƒ­ã‚¸ãƒƒã‚¯ ... å¤‰æ›´ãªã—) ...
    hub_counts = {}
    for p in processed_articles:
        if p.get('file_name', '').endswith('index.html'):
            hub_counts[p['file_name']] = 0
    for p in processed_articles:
        if not p.get('file_name', '').endswith('index.html'):
            parent_dir = os.path.dirname(p.get('file_name', ''))
            parent_hub = os.path.join(parent_dir, 'index.html').replace(os.path.sep, '/')
            if parent_hub in hub_counts:
                hub_counts[parent_hub] += 1
    balance_report = "| ãƒãƒ–ãƒšãƒ¼ã‚¸ | é…ä¸‹ã®è©³ç´°è¨˜äº‹æ•° |\n| :--- | :--- |\n"
    print("âœ… ç¾åœ¨ã®ã‚µã‚¤ãƒˆãƒãƒ©ãƒ³ã‚¹:")
    for hub, count in hub_counts.items():
        if 'legal/' not in hub and 'contact/' not in hub and 'projects/' not in hub:
             if 'about/' not in hub:
                balance_report += f"| {hub} | {count} |\n"
                print(f"  - {hub}: {count} ä»¶")

    # --- 5b. æˆ¦ç•¥çš„å„ªå…ˆåº¦ã®æ±ºå®š (å¤‰æ›´ãªã—) ---
    print("\n--- [ãƒ•ã‚§ãƒ¼ã‚º5b: æˆ¦ç•¥çš„å„ªå…ˆåº¦ã®æ±ºå®š] AIãŒåˆ†æä¸­ ---")
    analysis_target_articles = [
        p for p in processed_articles 
        if not p.get('file_name', '').startswith('projects/')
    ]
    print(f"\nâ„¹ï¸ 'projects/' ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’é™¤å¤–ã—ã€{len(analysis_target_articles)}ä»¶ã‚’åˆ†æå¯¾è±¡ã¨ã—ã¾ã™ã€‚")
    df_all_data = create_placeholder_data(analysis_target_articles) 
    priority_result = select_priority_section_by_data(
        gemini_client, df_all_data, CORPORATE_IDENTITY, 
        analysis_target_articles, balance_report 
    )
    priority_file = priority_result['file_name']
    # â¬‡ï¸ [ä¿®æ­£] å®‰å…¨è£…ç½®ã‚’è¿½åŠ 
        try:
            priority_section_info = next(p for p in processed_articles if p['file_name'] == priority_file)
        except StopIteration:
            print(f"âš ï¸ è­¦å‘Š: AIãŒé¸å®šã—ãŸ '{priority_file}' ãŒè¨ˆç”»ãƒªã‚¹ãƒˆã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: 'insights/index.html' ã¾ãŸã¯ãƒªã‚¹ãƒˆã«ã‚ã‚‹æœ€åˆã®ãƒãƒ–ãƒšãƒ¼ã‚¸ã‚’ä½¿ç”¨
            fallback_candidates = [
                p for p in processed_articles 
                if p['file_name'].endswith('index.html') and p['file_name'] != 'index.html'
            ]
            
            if fallback_candidates:
                priority_section_info = fallback_candidates[0] # ã¨ã‚Šã‚ãˆãšæœ€åˆã®å€™è£œã‚’ä½¿ã†
                priority_file = priority_section_info['file_name']
                print(f"âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ä»£ã‚ã‚Šã« '{priority_file}' ã‚’å¼·åŒ–å¯¾è±¡ã¨ã—ã¾ã™ã€‚")
            else:
                print("âŒ ã‚¨ãƒ©ãƒ¼: æœ‰åŠ¹ãªãƒãƒ–ãƒšãƒ¼ã‚¸ãŒè¨ˆç”»ãƒªã‚¹ãƒˆã«1ã¤ã‚‚ã‚ã‚Šã¾ã›ã‚“ã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚")
                sys.exit(1)
        # â¬†ï¸ [ä¿®æ­£] ã“ã“ã¾ã§
    print(f"âœ… [ãƒ•ã‚§ãƒ¼ã‚º5b å®Œäº†] æœ€å„ªå…ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒæ±ºå®šã—ã¾ã—ãŸã€‚")
    print(f"ğŸ¥‡ æœ€å„ªå…ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³: {priority_section_info['title']} (`{priority_file}`)")
    print(f"ğŸ”‘ é¸å®šç†ç”±: {priority_result['reason']}")

    # --- 6. è©³ç´°è¨˜äº‹ã®ä¼ç”» ---
    print("\n--- [ãƒ•ã‚§ãƒ¼ã‚º6: è©³ç´°è¨˜äº‹ã®ä¼ç”»] AIãŒä¼ç”»ä¸­ ---")
    
    # é€šã—ç•ªå·ã‚’å–å¾— (å¤‰æ›´ãªã—)
    max_article_num = 0
    for p in processed_articles:
        match = re.search(r'-(\d+)\.html$', p.get('file_name', ''))
        if match:
            num = int(match.group(1))
            if num > max_article_num: max_article_num = num
    start_number = max_article_num + 1
    print(f"â„¹ï¸ æ¬¡ã®è¨˜äº‹ç•ªå·ã¯ {start_number} ã‹ã‚‰é–‹å§‹ã—ã¾ã™ã€‚")
    
    # --- â¬‡ï¸ [ä¿®æ­£] è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ã®è¿½åŠ  ---
    max_retries = 3
    wait_time = 30 # æœ€åˆã®å¾…æ©Ÿæ™‚é–“ (ç§’)
    article_plans = None
    error_msg = ""

    for attempt in range(max_retries):
        print(f"\nğŸ“¢ AIã« {priority_section_info['title']} ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”¨ã®è¨˜äº‹ {DEFAULT_ARTICLE_COUNT} ä»¶ã®ä¼ç”»ã‚’ä¾é ¼ä¸­... (è©¦è¡Œ {attempt + 1}/{max_retries})")
        
        # å®Ÿéš›ã®APIå‘¼ã³å‡ºã—
        error_msg, article_plans = generate_priority_article_titles(
            gemini_client, priority_section_info, CORPORATE_IDENTITY, DEFAULT_ARTICLE_COUNT, start_number
        )

        if article_plans: # æˆåŠŸ
            break # ãƒªãƒˆãƒ©ã‚¤_ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹

        # å¤±æ•—
        print(f"âš ï¸ ä¼ç”»ã«å¤±æ•—: {error_msg}")
        
        # 503ã‚¨ãƒ©ãƒ¼ã‹ "overloaded" ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if "503" in str(error_msg) or "overloaded" in str(error_msg).lower():
            if attempt < max_retries - 1:
                print(f"   ...AIãƒ¢ãƒ‡ãƒ«ãŒæ··é›‘ã—ã¦ã„ã¾ã™ã€‚{wait_time}ç§’å¾…æ©Ÿã—ã¦å†è©¦è¡Œã—ã¾ã™ã€‚")
                time.sleep(wait_time)
                wait_time *= 2 # æ¬¡ã®å¾…æ©Ÿæ™‚é–“ã‚’2å€ã« (Exponential Backoff)
            else:
                # æœ€çµ‚è©¦è¡Œã§ã‚‚å¤±æ•—
                print(f"âŒ {max_retries}å›è©¦è¡Œã—ã¾ã—ãŸãŒã€APIãŒæ··é›‘ã—ã¦ã„ã¾ã™ã€‚")
        else:
            # 503ä»¥å¤–ã®ã‚¨ãƒ©ãƒ¼ (ä¾‹: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ©ãƒ¼ãªã©)
            print("âŒ APIã®æ··é›‘ã§ã¯ãªã„è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼ã®ãŸã‚ã€å†è©¦è¡Œã‚’åœæ­¢ã—ã¾ã™ã€‚")
            break # ãƒªãƒˆãƒ©ã‚¤_ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹

    # ãƒ«ãƒ¼ãƒ—çµ‚äº†å¾Œã€æœ€çµ‚çš„ã«æˆåŠŸã—ãŸã‹ãƒã‚§ãƒƒã‚¯
    if not article_plans:
        print(f"âŒ è¨˜äº‹ã®ä¼ç”»ã«å¤±æ•—ã—ãŸãŸã‚ã€å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚")
        sys.exit(1)
    # --- â¬†ï¸ [ä¿®æ­£]ã“ã“ã¾ã§ ---

    print(f"âœ… [ãƒ•ã‚§ãƒ¼ã‚º6 å®Œäº†] {len(article_plans)} ä»¶ã®æ–°è¦è¨˜äº‹ã‚’ä¼ç”»ã—ã¾ã—ãŸã€‚")
    
    # (æ—¥ä»˜è¿½åŠ  ... å¤‰æ›´ãªã—)
    current_time_iso = datetime.now().isoformat()
    for plan in article_plans:
        plan['created_at'] = current_time_iso
        plan['updated_at'] = "" 

    # --- 7. (æœ¬ç•ª) è©³ç´°è¨˜äº‹ã®HTMLç”Ÿæˆ ---
    print("\n--- [ãƒ•ã‚§ãƒ¼ã‚º7: è©³ç´°è¨˜äº‹ã®HTMLç”Ÿæˆ] ---")
    new_article_files_generated = [] 
    # (for ãƒ«ãƒ¼ãƒ— ... å¤‰æ›´ãªã—)
    for i, plan in enumerate(article_plans):
        target_dir = os.path.dirname(priority_section_info['file_name'])
        file_name = os.path.join(target_dir, plan.get('file_name', f'error-slug-{i}.html'))
        file_name = file_name.replace(os.path.sep, '/')
        article_plans[i]['file_name'] = file_name 
        print(f"\n--- ğŸ­ [æœ¬ç•ªç”Ÿæˆ] {plan['title']} ---")
        target_page_for_generation = {
            'title': plan['title'],
            'file_name': file_name,
            'purpose': plan['summary']
        }
        nav_list_for_generation = [
            {
                "file_name": p['file_name'], "title": p['title'],
                "purpose": p.get('summary', p.get('generated_purpose', '')) 
            } for p in processed_articles
        ]

        final_html_code = generate_single_page_html(
            gemini_client,
            target_page_for_generation,
            CORPORATE_IDENTITY,
            None,
            nav_list_for_generation,
            SITE_TYPE=SITE_TYPE, 
            retry_attempts=3, # (generate_single_page_html å´ã«ã‚‚ãƒªãƒˆãƒ©ã‚¤ãŒã‚ã‚‹)
            article_date=plan['created_at'] 
        )

        if "âŒ" not in final_html_code:
            generate_file_path = os.path.join(BASE_DIR, file_name)
            os.makedirs(os.path.dirname(generate_file_path), exist_ok=True)
            try:
                with open(generate_file_path, 'w', encoding='utf-8') as f:
                    f.write(final_html_code)
                print(f"âœ… [æœ¬ç•ªç”Ÿæˆ] ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆæˆåŠŸ: {generate_file_path}")
                new_article_files_generated.append(plan) 
            except Exception as e:
                print(f"âŒ [æœ¬ç•ªç”Ÿæˆ] ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå¤±æ•—: {e}")
        else:
            print(f"âŒ [æœ¬ç•ªç”Ÿæˆ] HTMLã‚³ãƒ¼ãƒ‰ç”Ÿæˆå¤±æ•—: {file_name}")

    # --- 8. ãƒãƒ–ãƒšãƒ¼ã‚¸ã®è‡ªå‹•æ›´æ–° ---
    print(f"\n--- [ãƒ•ã‚§ãƒ¼ã‚º8: ãƒãƒ–ãƒšãƒ¼ã‚¸ã®è‡ªå‹•æ›´æ–°] ---")
    # (all_content_plans çµ±åˆ ... å¤‰æ›´ãªã—)
    all_content_plans = integrate_content_data(processed_articles, article_plans)
    hub_path_to_update = priority_file
    hub_dir = os.path.dirname(hub_path_to_update)
    
    # (X Bot é€£æºç”¨ ... å¤‰æ›´ãªã—)
    newly_updated_hubs = []
    current_time_iso_update = datetime.now().isoformat()
    print(f"ğŸ­ {hub_path_to_update} ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã€é…ä¸‹ã®å…¨è¨˜äº‹ãƒªãƒ³ã‚¯ã‚’çµ„ã¿è¾¼ã¿ã¾ã™ã€‚")

    try:
        # (ãƒãƒ–ã®æ›´æ–°æ—¥ã‚’è¨˜éŒ² ... å¤‰æ›´ãªã—)
        parent_page_plan = next(p for p in all_content_plans if p['file_name'] == hub_path_to_update)
        parent_page_plan['updated_at'] = current_time_iso_update
        newly_updated_hubs.append(parent_page_plan) 
        
    except StopIteration:
        print(f"âŒ [ãƒãƒ–æ›´æ–°å¤±æ•—] è¨ˆç”»ãƒªã‚¹ãƒˆã«è¦ªãƒãƒ– ({hub_path_to_update}) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        sys.exit(1)

    parent_page_info_for_regeneration = {
        'file_name': parent_page_plan['file_name'],
        'title': parent_page_plan['title'],
        'purpose': parent_page_plan.get('summary', parent_page_plan.get('generated_purpose')) 
    }

    # (all_articles_in_section ... å¤‰æ›´ãªã—)
    all_articles_in_section = [
        p for p in all_content_plans 
        if os.path.dirname(p.get('file_name','')) == hub_dir and p.get('file_name','') != hub_path_to_update
    ]
    print(f"  -> {len(all_articles_in_section)} ä»¶ã®è©³ç´°è¨˜äº‹ï¼ˆæ–°æ—§å«ã‚€ï¼‰ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¾ã—ãŸã€‚")

    # (new_article_links_html ... å¤‰æ›´ãªã—)
    new_article_links_html = "<ul>"
    if not all_articles_in_section:
        new_article_links_html = "<p>ï¼ˆç¾åœ¨ã€ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®è©³ç´°è¨˜äº‹ã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰</p>"
    else:
        for plan in all_articles_in_section:
            link_path = os.path.basename(plan['file_name'])
            article_summary = plan.get('summary', plan.get('generated_purpose', '')) 
            new_article_links_html += f"<li><a href='{link_path}' class='text-blue-500 hover:underline'>{plan['title']}</a>: {article_summary}</li>"
    new_article_links_html += "</ul>"

    # (ãƒãƒ–ã® purpose ä¸Šæ›¸ã ... å¤‰æ›´ãªã—)
    parent_page_info_for_regeneration['purpose'] = f"""
    ã“ã®ãƒšãƒ¼ã‚¸ï¼ˆ{parent_page_info_for_regeneration['title']}ï¼‰ã¯ã€ä»¥ä¸‹ã®ã€Œ{len(all_articles_in_section)}ä»¶ã®å…¨è©³ç´°è¨˜äº‹ã€ã¸ã®å°ç·šã‚’å«ã‚€ãƒãƒ–ãƒšãƒ¼ã‚¸ã¨ã—ã¦æ©Ÿèƒ½ã—ã¾ã™ã€‚
    å…ƒã®ç›®çš„ï¼ˆ{parent_page_info_for_regeneration['purpose']}ï¼‰ã‚’è¦ç´„ã—ã¤ã¤ã€ã“ã‚Œã‚‰ã®æ–°ã—ã„è¨˜äº‹ã¸ã®æ˜ç¢ºãªå°ç·šï¼ˆç›®æ¬¡ï¼‰ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

    ã€{hub_dir} ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®å…¨è©³ç´°è¨˜äº‹ãƒªã‚¹ãƒˆã€‘
    {new_article_links_html}
    """
    
    # (nav_list_for_generation ... å¤‰æ›´ãªã—)
    nav_list_for_generation = [
        {
            "file_name": p['file_name'], "title": p['title'],
            "purpose": p.get('summary', p.get('generated_purpose', '')) 
        } for p in all_content_plans
    ]

    # (final_hub_code å‘¼ã³å‡ºã— ... å¤‰æ›´ãªã—)
    final_hub_code = generate_single_page_html(
        gemini_client,
        parent_page_info_for_regeneration,
        CORPORATE_IDENTITY,
        None,
        nav_list_for_generation,
        SITE_TYPE=SITE_TYPE, 
        retry_attempts=3,
        article_date=current_time_iso_update 
    )

    # (ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ ... å¤‰æ›´ãªã—)
    if "âŒ" not in final_hub_code:
        hub_file_path = os.path.join(BASE_DIR, parent_page_info_for_regeneration['file_name'])
        try:
            with open(hub_file_path, "w", encoding="utf-8") as f:
                f.write(final_hub_code)
            print(f"âœ… [ãƒãƒ–æ›´æ–°å®Œäº†] ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ãä¿å­˜ã—ã¾ã—ãŸ: {hub_file_path}")
        except Exception as e:
            print(f"âŒ [ãƒãƒ–æ›´æ–°å¤±æ•—] ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    else:
        print(f"âŒ [ãƒãƒ–æ›´æ–°å¤±æ•—] HTMLã®å†ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    # --- 9. (ãƒ¬ãƒãƒ¼ãƒˆ) å…¨ä½“è¨ˆç”»ã‚’MDãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ ---
    print("\n--- [æœ€çµ‚å‡¦ç†: å…¨ä½“è¨ˆç”»ã®ä¿å­˜] ---")
    os.makedirs(REPORTS_DIR, exist_ok=True)
    save_to_markdown(all_content_plans, REPORT_FILE)
    print(f"âœ… å…¨ä½“è¨ˆç”»ã‚’ {REPORT_FILE} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
    
    # --- 10. XæŠ•ç¨¿ç”¨ã®æ›´æ–°ãƒªã‚¹ãƒˆã‚’ä¿å­˜ (å¤‰æ›´ãªã—) ---
    print("\n--- [ãƒ•ã‚§ãƒ¼ã‚º10: XæŠ•ç¨¿ç”¨ã®æ›´æ–°ãƒªã‚¹ãƒˆã‚’ä¿å­˜] ---")
    output_for_x_bot = os.path.join(PROJECT_ROOT_PATH, "newly_updated_articles.json")
    SITE_BASE_URL = "https://lou-ark.github.io/sophia-echoes/"
    articles_for_x = []
    
    for plan in new_article_files_generated:
        articles_for_x.append({
            "theme": plan['title'],
            "keywords": ["AI", "QoL", "sophia-echoes", "çŸ¥è¦‹"], 
            "main_url": os.path.join(SITE_BASE_URL, plan['file_name']).replace(os.path.sep, '/'),
            "provided_summary": plan.get('summary', 'è¨˜äº‹ã®æ¦‚è¦') 
        })
        
    for plan in newly_updated_hubs:
         articles_for_x.append({
            "theme": f"æ›´æ–°: {plan['title']}", 
            "keywords": ["AI", "QoL", "sophia-echoes"],
            "main_url": os.path.join(SITE_BASE_URL, plan['file_name']).replace(os.path.sep, '/'),
            "provided_summary": plan.get('purpose', 'ãƒãƒ–ãƒšãƒ¼ã‚¸ã®æ¦‚è¦') 
        })

    if articles_for_x:
        try:
            with open(output_for_x_bot, 'w', encoding='utf-8') as f:
                json.dump(articles_for_x, f, ensure_ascii=False, indent=2)
            print(f"âœ… {len(articles_for_x)} ä»¶ã®æ›´æ–°æƒ…å ±ã‚’ {output_for_x_bot} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
        except Exception as e:
            print(f"âŒ XæŠ•ç¨¿ç”¨ãƒªã‚¹ãƒˆã®ä¿å­˜ã«å¤±æ•—: {e}")
    else:
        print("â„¹ï¸ Xã«é€šçŸ¥ã™ã‚‹æ–°è¦è¨˜äº‹ãƒ»æ›´æ–°ãƒãƒ–ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    # --- 11. ã‚¿ã‚°ã®è‡ªå‹•æŒ¿å…¥ (å¤‰æ›´ãªã—) ---
    print("\n--- [ãƒ•ã‚§ãƒ¼ã‚º11: GTM/AdSense ã‚¿ã‚°ã®è‡ªå‹•æŒ¿å…¥] ---")
    print("ç”Ÿæˆãƒ»æ›´æ–°ã•ã‚ŒãŸHTMLãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¿ã‚°ã‚’æŒ¿å…¥ã—ã¾ã™...")
    try:
        inject_tags_main()
    except Exception as e:
        print(f"âŒ ã‚¿ã‚°æŒ¿å…¥ãƒ—ãƒ­ã‚»ã‚¹ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        print("â„¹ï¸ ã‚¿ã‚°ã‚’æŒ¿å…¥ã™ã‚‹å ´åˆã¯ã€æ‰‹å‹•ã§ %run main_03_inject_tags.py ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

    print("--- ğŸ”„ HPæ”¹å–„ã‚µã‚¤ã‚¯ãƒ«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ å®Œäº† ---")

if __name__ == "__main__":
    PROJECT_ROOT_PATH = "/content/MySiteGen-Agent" 
    if PROJECT_ROOT_PATH not in sys.path:
        sys.path.append(PROJECT_ROOT_PATH)
    main()
